
## OpenMP
Estándar para programación paralela en sistema de memoria compartida. 
Se crean múltiples hebras para dividir el trabajo.
Las hebras se comunican a través de variables compartidas.

### Beneficios
- Permite desarrollar fácilmente aplicaciones paralelas eficientes y de tamaño medio.
- Es más útil en aplicaciones que manipulen arreglos y matrices grandes.


```c
#include <omp.h>

void main(){
	int ntasks = 3;

#pragma omp parallel num_threads(ntasks){
	printf("Hello World, numero de hebra = %d\n", omp_get_thread_num());
}
}
```

### Modelo OpenMP de ejecución
1. **Hebra inicial:** Encargada de iniciar el trabajo paralelo.
2. **Inicio de región paralela:** Cuando se encuentra con la directiva de pragma, se inicia una construcción paralela. La hebra maestra crea un grupo de hebras hijas que ejecutan el mismo código paralelo.
3. **Creación de hebras hijas.**
4. **Término de la región paralela:** Todas las hebras deben llegar a un punto de sincronización (**barrera implícita**). Todas las hebras se sincronizan antes de continuar.
5. **Continuación de la hebra maestra:** Cuando todas las hebras hijas finalizan y se sincronizan, solo la hebra maestra continúa la ejecución del código.
6. **Repetición del ciclo:** El programa puede encontrar nuevas regiones paralelas más adelante, donde se repetirán los pasos.

### Modelo OpenMP de memoria
- Todas las hebras tienen acceso a un lugar donde almacenar y recuperar variables compartidas.
- Cada hebra puede tener una visión temporal propia de la memoria. Además, cada una puede tener su propia memoria no accesible para otras hebras.
- Si varias hebras escriben una variable compartida sin sincronización, el valor final es no especificado.

### Modelo OpenMP de memoria (cont)
* Un valor escrito sobre una variable puede permanecer en la visión temporal de la hebra hasta que es forzada a actualizarse en la memoria.
* Una lectura de una variable puede retornar el valor en la visión temporal de la hebra, a menos que se fuerce la lectura de la memoria.
- La operación flush obliga consistencia entre la visión temporal de la memoria y la memoria, para esas variables. Sin embargo, no garantiza que una hebra lea el valor actualizado de una variable.

### Cláusulas de alcance
- Private (list): Variables serán privadas a cada hebra (variables locales). 
- Shared (list): Variables compartidas por todas las hebras del grupo de trabajo.

### Cálculo secuencial de $\pi$
```c
#define <stdio.h>
#define <math.h>
#define f(A) (sqrtf(1.0-(A*A)))
#define N 10000000

main() {
	float sum=0.0;
	int i;
	for (i=1;i<=N;i++) {
		x = 1.0*i/N;
		sum = sum+f(x);
	}
	pi = 4.0*sum/N;
	printf("pi = %f\n", pi);
}
```

### Cálculo secuencial Monte Carlo de $\pi$
```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#define f(A) (sqrt(1.0-(A*A)))
#define N 1000000000

main() {
	double sum=0.0, x, pi;
	int i;
	for (i=1;i<=N;i++) {
		x = drand48();
		sum = sum + f(x);
	}
	pi = 4.0*sum/N;
	printf("pi = %f\n", pi);
}
```

### Solución OpenMP Monte Carlo de $\pi$
```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#define f(A) (sqrt(1.0-(A*A)))
#define N 1000000000
#ifdef _OPENMP
#include <omp.h>
#endif
main() {
	double sum=0.0, x, pi;
	int i;
	double sum0 = 0.0;
	#pragma omp parallel private(x, sum0) shared(sum) num_threads(2)
	{
	#pragma omp for
		for (i=1;i<=N;i++) {
			x = drand48();
			sum0 = sum0+f(x);
		}
	#pragma omp critical
		sum += sum0;
	}
		pi = 4.0*sum/N;
		printf("pi = %f\n", pi);
}
```

### Directiva parallel: número de hebras
Para determinar el número de hebras requeridas para el bloque, se evalúan las siguientes reglas, en orden:
1. Si la clausula if está presente y se evalúa a cero (falso), el bloque es serializado.
2. Si la cláusula num_threads está presente, entonces el valor de la expresión de dicha cláusula es el número de hebras requeridas.

Nota: Serializar un bloque implica que, aunque haya un intento de paralelizar, el código termina ejecutándose de manera lineal, sin dividirse entre múltiples hebras.

```c
#pragma omp parallel num_threads(5)

# Crea 5 hebras
```

```c
...
#pragma omp parallel if(val) num_threads(12)

# Se crea 1 hebra si val = 0. 
# Si val != 0, se crean 12 hebras.
```

```c
omp_set_num_threads(3);
#pragma omp parallel

# Crea 3 hebras
```

```c
#pragma omp parallel
omp_set_num_threads(3)

# Número indedinido
```

### Hyperthreading
Tecnología que permite que un solo núcleo físico de un procesador se vea y actúe como si fueran dos núcleos lógicos (virtuales).
Permite que dos hilos de ejecución se ejecuten simultáneamente en el mismo núcleo físico. Esto se logra al aprovechar los recursos no utilizados de la CPU, permitiendo que ambos hilos compartan y utilicen esos recursos.

Incluir más hebras de forma exagerada puede contrarrestar el rendimiento que se busca tener.