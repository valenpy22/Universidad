## OpenMP
Estándar para programación paralela en sistema de memoria compartida. 
Se crean múltiples hebras para dividir el trabajo.
Las hebras se comunican a través de variables compartidas.

### Beneficios
- Permite desarrollar fácilmente aplicaciones paralelas eficientes y de tamaño medio.
- Es más útil en aplicaciones que manipulen arreglos y matrices grandes.


```c
#include <omp.h>

void main(){
	int ntasks = 3;

#pragma omp parallel num_threads(ntasks){
	printf("Hello World, numero de hebra = %d\n", omp_get_thread_num());
}
}
```

### Modelo OpenMP de ejecución
1. **Hebra inicial:** Encargada de iniciar el trabajo paralelo.
2. **Inicio de región paralela:** Cuando se encuentra con la directiva de pragma, se inicia una construcción paralela. La hebra maestra crea un grupo de hebras hijas que ejecutan el mismo código paralelo.
3. **Creación de hebras hijas.**
4. **Término de la región paralela:** Todas las hebras deben llegar a un punto de sincronización (**barrera implícita**). Todas las hebras se sincronizan antes de continuar.
5. **Continuación de la hebra maestra:** Cuando todas las hebras hijas finalizan y se sincronizan, solo la hebra maestra continúa la ejecución del código.
6. **Repetición del ciclo:** El programa puede encontrar nuevas regiones paralelas más adelante, donde se repetirán los pasos.

### Modelo OpenMP de memoria
- Todas las hebras tienen acceso a un lugar donde almacenar y recuperar variables compartidas.
- Cada hebra puede tener una visión temporal propia de la memoria. Además, cada una puede tener su propia memoria no accesible para otras hebras.
- Si varias hebras escriben una variable compartida sin sincronización, el valor final es no especificado.

### Modelo OpenMP de memoria (cont)
* Un valor escrito sobre una variable puede permanecer en la visión temporal de la hebra hasta que es forzada a actualizarse en la memoria.
* Una lectura de una variable puede retornar el valor en la visión temporal de la hebra, a menos que se fuerce la lectura de la memoria.
- La operación flush obliga consistencia entre la visión temporal de la memoria y la memoria, para esas variables. Sin embargo, no garantiza que una hebra lea el valor actualizado de una variable.

### Cláusulas de alcance
- Private (list): Variables serán privadas a cada hebra (variables locales). 
- Shared (list): Variables compartidas por todas las hebras del grupo de trabajo.

### Cálculo secuencial de $\pi$
```c
#define <stdio.h>
#define <math.h>
#define f(A) (sqrtf(1.0-(A*A)))
#define N 10000000

main() {
	float sum=0.0;
	int i;
	for (i=1;i<=N;i++) {
		x = 1.0*i/N;
		sum = sum+f(x);
	}
	pi = 4.0*sum/N;
	printf("pi = %f\n", pi);
}
```

### Cálculo secuencial Monte Carlo de $\pi$
```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#define f(A) (sqrt(1.0-(A*A)))
#define N 1000000000

main() {
	double sum=0.0, x, pi;
	int i;
	for (i=1;i<=N;i++) {
		x = drand48();
		sum = sum + f(x);
	}
	pi = 4.0*sum/N;
	printf("pi = %f\n", pi);
}
```

### Solución OpenMP Monte Carlo de $\pi$
```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#define f(A) (sqrt(1.0-(A*A)))
#define N 1000000000
#ifdef _OPENMP
#include <omp.h>
#endif
main() {
	double sum=0.0, x, pi;
	int i;
	double sum0 = 0.0;
	#pragma omp parallel private(x, sum0) shared(sum) num_threads(2)
	{
	#pragma omp for
		for (i=1;i<=N;i++) {
			x = drand48();
			sum0 = sum0+f(x);
		}
	#pragma omp critical
		sum += sum0;
	}
		pi = 4.0*sum/N;
		printf("pi = %f\n", pi);
}
```

### Directiva parallel: número de hebras
Para determinar el número de hebras requeridas para el bloque, se evalúan las siguientes reglas, en orden:
1. Si la clausula if está presente y se evalúa a cero (falso), el bloque es serializado.
2. Si la cláusula num_threads está presente, entonces el valor de la expresión de dicha cláusula es el número de hebras requeridas.

Nota: Serializar un bloque implica que, aunque haya un intento de paralelizar, el código termina ejecutándose de manera lineal, sin dividirse entre múltiples hebras.

```c
#pragma omp parallel num_threads(5)

# Crea 5 hebras
```

```c
...
#pragma omp parallel if(val) num_threads(12)

# Se crea 1 hebra si val = 0. 
# Si val != 0, se crean 12 hebras.
```

```c
omp_set_num_threads(3);
#pragma omp parallel

# Crea 3 hebras
```

```c
#pragma omp parallel
omp_set_num_threads(3)

# Número indedinido
```

### Hyperthreading
Tecnología que permite que un solo núcleo físico de un procesador se vea y actúe como si fueran dos núcleos lógicos (virtuales).
Permite que dos hilos de ejecución se ejecuten simultáneamente en el mismo núcleo físico. Esto se logra al aprovechar los recursos no utilizados de la CPU, permitiendo que ambos hilos compartan y utilicen esos recursos.

Incluir más hebras de forma exagerada puede contrarrestar el rendimiento que se busca tener.

### Atributos de compartición en parallel
El atributo de compartición de una variable referenciada dentro de una construcción se determina por una de las siguientes modalidades:
- Predeterminada: Definidas antes de comenzar la construcción.
- Explícitamente determinada: Definidas por cláusulas de la construcción.
- Implícitamente determinada

### Atributo de compartición predeterminado
- Variables automáticas declaradas en un scope dentro de la construcción son **private**.
- Los objetos con almacenamiento dinámico son **shared**.
- La variable en un for o parallel for son **private**.
- Variables con almacenamiento estático (**static**) declaradas en un scope dentro de la construcción son **shared**.

```c
#pragma omp parallel
{
	int tid = get...();
	// Scope
}
```

```c
#pragma omp parallel{
	for(i = 0; i < N; i++){
	}
	// Es privado
	
	static float f = 4.0; // Variable compartida por todas las hebras.
}
```

```c
int main(void){
	int i;
	chat *p = malloc(10);
	strcpy(p, "hola");
	printf("%s\n", p);
	#pragma omp parallel num_threads(5)
	{
		int itd = omp_get_thread_num();
		static int j = -1;
		if(tid == 0){
			strcpy(p, "chao");
			j = 5;
			printf("j = %d\n", j);
		}
		// Este for es compartido ya que está lejos del #pragma parallel
		for(i = 0; i < 2; i++){
			printf("tid = %d, i = %d, %s, j = %d\n", tid, i, p, j);
		}
	}
}
```

### Atributo de compartición explícito
Una variable referenciada dentro del alcance de una construcción, posee un atributo de compartición explícitamente determinado cuando aparece en la lista de una de las cláusulas de compartición de la construcción.
```c
int main(void){
	int i;
	chat *p = malloc(10);
	strcpy(p, "hola");
	printf("%s\n", p);
	#pragma omp parallel num_threads(5) private(i)
	{
		int itd = omp_get_thread_num();
		static int j = -1;
		if(tid == 0){
			strcpy(p, "chao");
			j = 5;
			printf("j = %d\n", j);
		}
		// Este for es compartido ya que está lejos del #pragma parallel
		for(i = 0; i < 2; i++){
			printf("tid = %d, i = %d, %s, j = %d\n", tid, i, p, j);
		}
	}
}

```

### Atributo de compartición implícito
Una variable referenciada dentro del alcance de una construcción, posee un atributo de compartición implícitamente determinada, es aquella que no aparece en la lista de cláusulas de compartición, no tienen atributos predeterminados.

- En una región parallel o task el atributo está determinado por la cláusula **default**, si está presente. Si no hay, la variable es **shared**.

```c
#pragma omp parallel{
	for(i = 0; i < N; i++){
	}
	// Es privado
	
	static float f = 4.0; // Variable compartida por todas las hebras.
	{
		int j; // Se hereda de for(i)...
	}
}
```

### Default
- default (shared): Todas las variables con atributos implícitos son **shared**.
- default (none): Especifica que la referencia a cualquier variable no asume ningún defecto. Luego, si existe una referencia a una variable, debe cumplirse que:
1. La variable está explícitamente listada en una cláusula de compartición.
2. Está declarada en la construcción paralela.
3. Es un objeto const.
4. Es la variable que controla el loop.
5. Es threadprivate.

### private vs firstprivate

Con private no se copia el valor externo, en cambio con firstprivate si se copia el valor de arriba.
- private: Establece cuáles variables son privadas a las hebras, y no especifica cómo estas deben ser inicializadas.
- firstprivate: Dice cuáles variables son privadas y especifica que deben ser inicializadas con el valor de la variable al comenzar el bloque paralelo.

![[Pasted image 20241007101913.png]]

### Shared y modelo de memoria OpenMP
- shared: Por defecto, todas las variables declaradas en el scope en que se encuentra la directiva parallel son globales en el bloque paralelo.
- Consistencia relajada: El modelo de memoria de openMP requiere de mucho cuidado cuando se trabaja con variables **shared**.

![[Pasted image 20241007102140.png]]![[Pasted image 20241007102241.png]]

## Construcciones para repartir el trabajo
No se crean nuevas hebras, sino que se usan las ya existentes.
- for
- sections
- single

Deben existir dentro de parallel.

### Ejemplo con for
```c
#define N 100

main(){
	int imagen[N];
	int j;
	...
	#pragma omp parallel private(j){
		#pragma omp for
		for(j = 0; j < N; j++){
			imagen[j] = 2*imagen[j];
		}
		// Hay N/2 operaciones.
	}
}
```

### Construcción for y schedule
schedule(kind, size) especifica cómo serán repartidas las iteraciones:
- static: Las iteraciones se dividen en porciones de tamaño size y asignadas estáticamente en round-robin a las hebras. Si no se especifica, la división se hace en porciones aproximadamente iguales en tamaño.
- dynamic: Se asigna a cada hebra una porción size en forma dinámica. Cuando una hebra termina su porción, solicita una nueva porción de tamaño size.
- guided: Opera como dynamic, pero las porciones son cada vez más pequeñas.
- runtime: La decisión se posterga hasta tiempo de ejecución.

### Static
```c
int i;
#pragma omp parallel num_threads(2)
	#pragma omp for schedule(static, 2)
		for (i=0; i < 9; i++)
		printf("tid %d, i = %d\n", omp_get_thread_num(), i);
```

La 0 -> 0 y 1
La 1 -> 2 y 3
La 0 -> 4 y 5
La 1 -> 6 y 7
La 0 -> 8

```c
int i;
#pragma omp parallel num_threads(2)
{
	#pragma omp for schedule(static, 2)
		for (i=0; i < 9; i++) {
			printf("tid %d, i = %d\n", omp_get_thread_num(), i);
			if (omp_get_thread_num() == 0) sleep(5);
		}
}
```

### Dynamic
```c
#pragma omp parallel num_threads(2)
{
	#pragma omp for schedule(dynamic, 2)
		for (i=0; i < 9; i++)
			printf("%d, i = %d\n",
				omp_get_thread_num(), i);
}
```

```c
#pragma omp parallel num_threads(2)
{
	#pragma omp for schedule(dynamic, 2)
		for (i=0; i < 9; i++) {
			printf("%d, i = %d\n",
			omp_get_thread_num(), i);
		if (omp_get_thread_num() == 0) sleep(5);
		}
}
```

### Barrera implícita y nowait
Al término de un bloque paralelo existe una barrera implícita, es decir, las hebras deben esperar a que todas terminen el bloque para continuar.

Nowait elimina la barrera implícita.

```c
#pragma omp parallel num_threads(2)
{
	#pragma omp for schedule(dynamic, 2) nowait
	for (i=0; i < 9; i++) {
		printf("%d, i = %d\n", omp_get_thread_num(), i);
		if (omp_get_thread_num() == 0)
			sleep(5);
	}
	printf("%d sali\n", omp_get_thread_num());
}
```

### Ordered
```c
#pragma omp parallel num_threads(2)
{
	#pragma omp for schedule(dynamic, 2) ordered
	for (i=0; i < 9; i++) {
		f(i);
		#pragma omp ordered
		printf("%d, i = %d\n", omp_get_thread_num(), i);
		// Se va a secuencializar según el for
}

/*
Salida

0, i = 0
0, i = 1
1, i = 2
1, i = 3
0, i = 4
0, i = 5
1, i = 6
1, i = 7
0, i = 8
*/
```

### Reduction en un for
```c
int sum = 0; //shared variable
#pragma omp parallel num_threads(2)
{
	int tid = omp_get_thread_num();
	#pragma omp for reduction(+:sum)
	for (i=0; i < 7; i++)
		// Reduction privatiza la variable y la inicializa con la variable que está afuera.
		// No permite que sea suma por vectores, siempre una variable escalar.
		sum += i*i;
	printf("%d con sum = %d\n", tid, sum);
}
printf("total sum = %d\n", sum);
```

```c
int sum = 0; //shared variable
#pragma omp parallel num_threads(2) reduction(+:sum)
{
	int tid = omp_get_thread_num();
	#pragma omp for
	for (i=0; i < 7; i++)
		sum += i*i;
	printf("%d con sum = %d\n", tid, sum);
}
printf("total sum = %d\n", sum);
```

### Construcción sections, con section
Usada para paralelizar un conjunto de bloques entre las hebras de la región paralela (es decir, debe aparecer en una región parallel).

![[Pasted image 20241007104412.png]]

### Ejemplo con sections
```c
int sum = 0;
#pragma omp parallel num_threads(3) reduction(+:sum)
{
	#pragma omp sections
	{
		#pragma omp section
		{
			sum = 1;
			printf("%d, en section 0\n", omp_get_thread_num());
		}
		#pragma omp section
		{
			sum = 2;
			printf("%d, en section 1\n", omp_get_thread_num());
		}
		#pragma omp section
		{
			sum = 3;
			printf("%d, en section 2\n", omp_get_thread_num());
		}
	}
}
printf("total sum = %d\n", sum);
```

Si el número de hebras participantes es mayor que el número de sections, simplemente algunas no hacen nada.

```c
int sum = 0;
#pragma omp parallel num_threads(3) reduction(+:sum)
{
	#pragma omp sections
	{
		#pragma omp section
		{
			sum = 1;
			printf("%d, en section 0\n", omp_get_thread_num());
		}
		#pragma omp section
		{
			sum = 2;
			printf("%d, en section 1\n", omp_get_thread_num());
		}
		#pragma omp section
		{
			sum = 3;
			printf("%d, en section 2\n", omp_get_thread_num());
		}
	}
}
printf("total sum = %d\n", sum);
```

### Condición de carrera en sections
Si el número de hebras es menor que el número de section, algunas hebras realizarán más de un section produciendo resultados erróneos.
```c
int sum = 0;
#pragma omp parallel num_threads(2) reduction(+:sum)
{
	#pragma omp sections
	{
		#pragma omp section
		{
			sum = 1;
			printf("%d, en section 0\n", omp_get_thread_num());
		}
		#pragma omp section
		{
			sum = 2;
			printf("%d, en section 1\n", omp_get_thread_num());
		}
		#pragma omp section
		{
			sum = 3;
			printf("%d, en section 2\n", omp_get_thread_num());
		}
	}
}
printf("total sum = %d\n", sum);
```

Algunas secciones pueden ser ejecutadas por los mismos hilos de forma secuencial. Esto produce un comportamiento incorrecto porque las variables compartidas, como sum, pueden ser sobrescritas por diferentes secciones, lo que genera condiciones de carrera.

### Construcción single
Especifica que el bloque asociado se ejecuta por sólo una hebra del equipo.
Single es útil también para escribir mensajes de depuración.
```c
void work1() { ... }
void work2() { ... }
main() {
#pragma omp parallel num_threads(5)
{
	#pragma omp single
	printf("Invocando work1()\n");
	work1();
	#pragma omp single
	printf("Fin work1()\n");
	#pragma omp single
	printf("Invocando work2()\n");
	work2();
	#pragma omp single
	printf("Fin work2()\n");
}
}
```

### lastprivate
Solo se aplica a directivas de compartición de trabajo (for, section).
Último valor que toman las variables de esta lista son asignadas a los objetos originales.
Se refiere al valor después de la última iteración, o al valor después de la ejecución de la última sección.
```c
void getValue(int *s) { scanf("%d\n", s); }
void useValue(int s) { printf("%d\n", s); }
int main (void)
{
	int x = 10;
	omp_set_num_threads(3);
	#pragma omp parallel firstprivate(x)
	{
	#pragma omp single copyprivate(x)
	getValue(&x);
	useValue(x);
}
```

### threadprivate
Crea una copia privada de cada variable listada en la directiva, a cada hebra, que bajo ciertas circunstancias es global o estática a la hebra.
```c
int x;
#pragma omp threadprivate(x)
main() {
	int tid;
	omp_set_num_threads(3);
#pragma omp parallel private(tid)
{
	tid = omp_get_thread_num();
	x = 10*tid + 1;
	printf("Dentro de parallel 1. Hebra = %d con x = %d\n", tid, x);
}
	printf("Fuera de parallel. Hebra = %d con x = %d\n", tid, x);
#pragma omp parallel private(tid)
{
	tid = omp_get_thread_num();
	printf("Dentro de parallel 2. Hebra = %d con x = %d\n", tid, x);
}
}
/*
Dentro de parallel 1. Hebra = 0 con x = 1
Dentro de parallel 1. Hebra = 2 con x = 21
Dentro de parallel 1. Hebra = 1 con x = 11
Fuera de parallel. Hebra = 0 con x = 1
Dentro de parallel 2. Hebra = 1 con x = 11
Dentro de parallel 2. Hebra = 2 con x = 21
Dentro de parallel 2. Hebra = 0 con x = 1
*/
```

### Uso incorrecto de threadprivate
```c
int a[1000];
#pragma omp threadprivate(a)
int main(int argc, char **argv)
{
	int i;
	int sum = 0;
#pragma omp parallel for schedule(static, 4)
	for (i = 0; i < 1000; i++) {
		a[i] = i;
	}
#pragma omp parallel for reduction (+:sum) schedule(static, 8)
	for (i = 0; i < 1000; i++) {
		sum = sum + a[i];
	}
	printf("%d\n", sum);
}
// Resultado
// 126858
```

### Cláusula inicialización de variables threadprivate
- copyin (lista-variables): Causa que las variables en la lista threadprivate tomen los valores que la hebra maestra tiene, justo antes de entrar a la región paralela. También puede usarse en construcciones parallel for y parallel sections.

### Construcciones para sincronización
- master: Especifica el bloque estructurado asociado es ejecutado sólo por la hebra maestra del equipo. No existe barrera implícita al comienzo ni al final del bloque estructurado.
- critical: Restringe la ejecución del bloque estructurado asociado, a una hebra a la vez. Es decir, funciona parecido a una sección crítica.
- barrier: Sincroniza las hebras de un equipo. Cuando una hebra llega a esta construcción, espera a que todas las hebras del equipo lleguen.
- atomic: Asegura que una localización específica de memoria es actualizada atómicamente. Si la expresión es simple, es preferible usar atomic en vez de critical.
- flush: Especifica un punto de sincronización en el cual se asegura que todas las hebras tengan una visión consistente de ciertos objetos (variables) en memoria. Está implícito en todo, a menos que exista una directiva nowait.

El flush es más barato que el barrier, porque:
1. Uno puede determinar la lista de las variables a actualizar.
2. Es más rápido flush.

### Funciones de librerías para *timing*
```c
double start;
double end;
start = omp\_get\_wtime();
...
end = omp\_get\_wtime();
printf("Tiempo usado = %f sec.\n", end-start);
```